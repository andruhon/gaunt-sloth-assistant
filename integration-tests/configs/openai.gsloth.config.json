{
  "llm": {
    "type": "openai",
    "model": "gpt-4o"
  },
  "canInterruptInferenceWithEsc": false,
  "streamSessionInferenceLog": false
}
